Our main contributions are summarized below.
(1) We propose a Byzantine-robust federation learning scheme based on the idea of anomaly detection: FLAD, which builds an anomaly detector based on neural networks and clustering models to detect and reject anomalous parameters uploaded by malicious clients, truly achieving aggregation only for honest parameters.
(2) FLAD is the first model attack defense scheme that uses neural network models to adaptively learn the internal features of honest parameters and thus measure the degree of similarity of different parameters. The scheme avoids the limitations that exist in traditional measures of similarity using cosine similarity, Pearson correlation coefficient, L2 distance, etc.
(3) In FLAD, clean server datasets are used to bootstrap trust in local parameters. Thus, the number of malicious attackers can change dynamically in each iteration and the method is fully applicable when there are a large number or even up to half of the attackers in the system.
(4) We conducted extensive experiments on real datasets to evaluate our FLAD. the effectiveness of FLAD was comprehensively evaluated by using different datasets, various different attack and defense methods, different attacker number fractions, etc. The experimental results show that FLAD has high global accuracy and good robustness against various existing poisoning attacks, evenincluding adaptive attacks.
